{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7380fc-ec2f-449a-92a2-c17df1d529fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import heterodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a1b460-a990-4f9e-8e62-6b77cfd1e15b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3cb1f3-7a6e-4837-9941-68af2be54607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bba970-0c80-4152-809f-5f10acf1f168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e8494-9bd1-4278-a769-7418d5fee513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop():\n",
    "    epoch_0 = 0\n",
    "    for epoch in range(epoch_0, self.autoencoder_num_epochs):\n",
    "                epoch_loss = []\n",
    "                print(\"Experiment: autoencoder {0}: training Epoch = \".format(self.autoencoder), epoch+1, 'out of', self.autoencoder_num_epochs, 'epochs')\n",
    "    \n",
    "                # Loop through all the train data using the data loader\n",
    "                for ii, (dem, ob, ac, l, t, scores, rewards, idx) in enumerate(self.train_loader):\n",
    "                    # print(\"Batch {}\".format(ii),end='')\n",
    "                    dem = dem.to(device)  # 5 dimensional vector (Gender, Ventilation status, Re-admission status, Age, Weight)\n",
    "                    ob = ob.to(device)    # 33 dimensional vector (time varying measures)\n",
    "                    ac = ac.to(device) # actions\n",
    "                    l = l.to(device)\n",
    "                    t = t.to(device)\n",
    "                    scores = scores.to(device)\n",
    "                    idx = idx.to(device)\n",
    "                    loss_pred = 0\n",
    "    \n",
    "                    # Cut tensors down to the batch's largest sequence length... Trying to speed things up a bit...\n",
    "                    max_length = int(l.max().item())\n",
    "    \n",
    "                    # The following losses are for DDM and will not be modified by any other approach\n",
    "                    train_loss, dec_loss, inv_loss = 0, 0, 0\n",
    "                    model_loss, recon_loss, forward_loss = 0, 0, 0                    \n",
    "                        \n",
    "                    # Set training mode (nn.Module.train()). It does not actually trains the model, but just sets the model to training mode.\n",
    "                    self.gen.train()\n",
    "                    self.pred.train()\n",
    "    \n",
    "                    ob = ob[:,:max_length,:]\n",
    "                    dem = dem[:,:max_length,:]\n",
    "                    ac = ac[:,:max_length,:]\n",
    "                    scores = scores[:,:max_length,:]\n",
    "                    \n",
    "                    # Special case for CDE\n",
    "                    # Getting loss_pred and mse_loss\n",
    "                    if self.autoencoder == 'CDE':\n",
    "                        loss_pred, mse_loss, _ = self.container.loop(ob, dem, ac, scores, l, max_length, self.context_input, corr_coeff_param = self.corr_coeff_param, device = device, coefs = self.train_coefs, idx = idx)\n",
    "                    else:\n",
    "                        loss_pred, mse_loss, _ = self.container.loop(ob, dem, ac, scores, l, max_length, self.context_input, corr_coeff_param = self.corr_coeff_param, device=device, autoencoder = self.autoencoder)   \n",
    "    \n",
    "                    self.optimizer.zero_grad()\n",
    "                    \n",
    "                    if self.autoencoder != 'DDM':\n",
    "                        loss_pred.backward()\n",
    "                        self.optimizer.step()\n",
    "                        epoch_loss.append(loss_pred.detach().cpu().numpy())                \n",
    "                    else:\n",
    "                        # For DDM\n",
    "                        train_loss, dec_loss, inv_loss, model_loss, recon_loss, forward_loss, corr_loss, loss_pred = loss_pred\n",
    "                        train_loss = forward_loss + self.inv_loss_coef*inv_loss + self.dec_loss_coef*dec_loss - self.corr_coeff_param*corr_loss.sum()\n",
    "                        train_loss.backward()\n",
    "                        # Clipping gradients to prevent exploding gradients\n",
    "                        torch.nn.utils.clip_grad_norm(self.all_params, self.max_grad_norm)\n",
    "                        self.optimizer.step()\n",
    "                        epoch_loss.append(loss_pred.detach().cpu().numpy())\n",
    "                                            \n",
    "                self.autoencoding_losses.append(epoch_loss)\n",
    "                if (epoch+1)%self.saving_period == 0: # Run validation and also save checkpoint\n",
    "                    \n",
    "                    #Computing validation loss\n",
    "                    epoch_validation_loss = []\n",
    "                    with torch.no_grad():\n",
    "                        for jj, (dem, ob, ac, l, t, scores, rewards, idx) in enumerate(self.val_loader):\n",
    "    \n",
    "                            dem = dem.to(device)\n",
    "                            ob = ob.to(device)\n",
    "                            ac = ac.to(device)\n",
    "                            l = l.to(device)\n",
    "                            t = t.to(device)\n",
    "                            idx = idx.to(device)\n",
    "                            scores = scores.to(device)\n",
    "                            loss_val = 0\n",
    "    \n",
    "                            # Cut tensors down to the batch's largest sequence length... Trying to speed things up a bit...\n",
    "                            max_length = int(l.max().item())                        \n",
    "                            \n",
    "                            ob = ob[:,:max_length,:]\n",
    "                            dem = dem[:,:max_length,:]\n",
    "                            ac = ac[:,:max_length,:] \n",
    "                            scores = scores[:,:max_length,:] \n",
    "                            \n",
    "                            self.gen.eval()\n",
    "                            self.pred.eval()    \n",
    "                            \n",
    "                            if self.autoencoder == 'CDE':\n",
    "                                loss_val, mse_loss, _ = self.container.loop(ob, dem, ac, scores, l, max_length, corr_coeff_param = 0, device = device, coefs = self.val_coefs, idx = idx)\n",
    "                            else:\n",
    "                                loss_val, mse_loss, _ = self.container.loop(ob, dem, ac, scores, l, max_length, self.context_input, corr_coeff_param = 0, device=device, autoencoder = self.autoencoder)                                                 \n",
    "                            \n",
    "                            if self.autoencoder in ['DST', 'ODERNN', 'CDE']:\n",
    "                                epoch_validation_loss.append(mse_loss)\n",
    "                            elif self.autoencoder == \"DDM\":\n",
    "                                epoch_validation_loss.append(loss_val[-1].detach().cpu().numpy())\n",
    "                            else:\n",
    "                                epoch_validation_loss.append(loss_val.detach().cpu().numpy())\n",
    "                        \n",
    "                            \n",
    "                    self.autoencoding_losses_validation.append(epoch_validation_loss)\n",
    "    \n",
    "                    save_dict = {'epoch': epoch,\n",
    "                            'gen_state_dict': self.gen.state_dict(),\n",
    "                            'pred_state_dict': self.pred.state_dict(),\n",
    "                            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                            'loss': self.autoencoding_losses,\n",
    "                            'validation_loss': self.autoencoding_losses_validation\n",
    "                            }\n",
    "                    \n",
    "                    if self.autoencoder == 'DDM':\n",
    "                        save_dict['dyn_state_dict'] = self.dyn.state_dict()\n",
    "                        \n",
    "                    try:\n",
    "                        torch.save(save_dict, self.checkpoint_file)\n",
    "                        # torch.save(save_dict, self.checkpoint_file[:-3] + str(epoch) +'_.pt')\n",
    "                        np.save(self.data_folder + '/{}_losses.npy'.format(self.autoencoder.lower()), np.array(self.autoencoding_losses))\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "    \n",
    "                    \n",
    "                    try:\n",
    "                        np.save(self.data_folder + '/{}_validation_losses.npy'.format(self.autoencoder.lower()), np.array(self.autoencoding_losses_validation))\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        \n",
    "                #Final epoch checkpoint\n",
    "                try:\n",
    "                    save_dict = {\n",
    "                                'epoch': self.autoencoder_num_epochs-1,\n",
    "                                'gen_state_dict': self.gen.state_dict(),\n",
    "                                'pred_state_dict': self.pred.state_dict(),\n",
    "                                'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                                'loss': self.autoencoding_losses,\n",
    "                                'validation_loss': self.autoencoding_losses_validation,\n",
    "                                }\n",
    "                    if self.autoencoder == 'DDM':\n",
    "                        save_dict['dyn_state_dict'] = self.dyn.state_dict()\n",
    "                        torch.save(self.dyn.state_dict(), self.dyn_file)\n",
    "                    torch.save(self.gen.state_dict(), self.gen_file)\n",
    "                    torch.save(self.pred.state_dict(), self.pred_file)\n",
    "                    torch.save(save_dict, self.checkpoint_file)\n",
    "                    np.save(self.data_folder + '/{}_losses.npy'.format(self.autoencoder.lower()), np.array(self.autoencoding_losses))\n",
    "                except Exception as e:\n",
    "                        print(e)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f2ca7-a635-4e38-aeb2-20e843f8eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.node_time_dict = {\n",
    "    \"user\": torch.tensor([1, 3, 5, 7]),  # Timestamps for user nodes\n",
    "    \"item\": torch.tensor([2, 4, 6, 8]),  # Timestamps for item nodes\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be726955-af7a-4c98-8f10-094388cae55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @timeit\n",
    "def time_select_up_to_t(dataset, t):\n",
    "    \"\"\"Select nodes and edges up to and including time step t.\n",
    "    @param t: time index (inclusive)\n",
    "    @return: HeteroData, with sliced nodes and edges based on time.\n",
    "    \"\"\"\n",
    "    dt = HeteroData()\n",
    "    d = dataset\n",
    "\n",
    "    # Get node timestamps (if they exist)\n",
    "    node_time_dict = getattr(d, \"node_time_dict\", {})  # Use empty dict if node_time_dict doesn't exist\n",
    "\n",
    "    # Copy node information up to and including time step t\n",
    "    for ntype, value in d.x_dict.items():\n",
    "        if ntype in node_time_dict:  # If node type has time information\n",
    "            mask = (node_time_dict[ntype] <= t).squeeze(-1)  # Filter nodes based on time\n",
    "            dt[ntype].x = value[mask]  # Copy node features for filtered nodes\n",
    "            if \"num_nodes\" in d[ntype].keys():\n",
    "                dt[ntype].num_nodes = mask.sum().item()  # Update number of nodes\n",
    "        else:  # If node type has no time information, copy all nodes\n",
    "            dt[ntype].x = value\n",
    "            if \"num_nodes\" in d[ntype].keys():\n",
    "                dt[ntype].num_nodes = d[ntype].num_nodes\n",
    "\n",
    "    # Get edge timestamps and edge indices\n",
    "    dea = d.edge_time_dict\n",
    "    dei = d.edge_index_dict\n",
    "\n",
    "    # Filter edges up to and including time step t\n",
    "    for etype in dea:\n",
    "        mask = (dea[etype] <= t).squeeze(-1)  # Include all edges with time <= t\n",
    "        dt[etype].edge_index = dei[etype][:, mask]\n",
    "        dt[etype].edge_time = dea[etype][mask]\n",
    "\n",
    "    return dt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-virtualenv-name",
   "language": "python",
   "name": "my-virtualenv-name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
