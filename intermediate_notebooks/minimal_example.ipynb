{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff4bb2b6-29dc-4da5-82e9-16bf54c54420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f944336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/taiskha/Master Thesis/code/rl_representations_main/scripts\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87400c27",
   "metadata": {},
   "source": [
    "copy stuff from train model below and mocify the original file but in a way that does not interfere with the original code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9680adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import click\n",
    "import yaml\n",
    "import numpy as np\n",
    "from experiment import Experiment\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "\n",
    "# ROOT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "# sys.path.append(ROOT_DIR)\n",
    "\n",
    "domain = 'sepsis'\n",
    "autoencoder = 'HTGNN'\n",
    "\n",
    "def run(autoencoder, domain, options):\n",
    "    dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "    params = yaml.safe_load(open(os.path.join(dir_path, '../configs/common.yaml'), 'r'))    \n",
    "    cfg_file = os.path.join(dir_path, '../configs/config_' + domain + f'_{autoencoder.lower()}.yaml')\n",
    "\n",
    "    bc_config = yaml.safe_load(open(os.path.join(dir_path, '../configs/config_behavCloning.yaml'), 'r'))\n",
    "\n",
    "    model_params = yaml.safe_load(open(cfg_file, 'r'))\n",
    "    \n",
    "    if autoencoder == 'CDE':\n",
    "        model_params['coefs_folder'] =  os.path.join(params['storage_path'], model_params['coefs_folder'])\n",
    "            \n",
    "    # Iterating over the keys in model_params and replacing the values in params merging the two dictionaries\n",
    "    for i in model_params:\n",
    "        params[i] = model_params[i]        \n",
    "    \n",
    "    # Extract BC network number of nodes\n",
    "    params['bc_num_nodes'] = bc_config['num_nodes']\n",
    "   \n",
    "\n",
    "    # Overriding params from config file with command line options if provided\n",
    "    for opt in options:\n",
    "        print(opt)\n",
    "        assert opt[0] in params\n",
    "        dtype = type(params[opt[0]])\n",
    "        if dtype == bool:\n",
    "            new_opt = False if opt[1] != 'True' else True\n",
    "        else:\n",
    "            new_opt = dtype(opt[1])\n",
    "        params[opt[0]] = new_opt\n",
    "\n",
    "    # Printing final parameters\n",
    "    print('Parameters ')\n",
    "    for key in params:\n",
    "        print(key, params[key])\n",
    "    print('=' * 30)\n",
    "\n",
    "    # process param keys and values to match input to Cortex\n",
    "    # what is Cortex? \n",
    "    if params['device'] == 'cuda':\n",
    "        if torch.cuda.is_available():\n",
    "            params['device'] = torch.device('cuda')\n",
    "        else:\n",
    "            params['device'] = torch.device('cpu')\n",
    "\n",
    "    random_seed = params['random_seed']\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    random_state = np.random.RandomState(random_seed)\n",
    "    # rng is not used in the code later\n",
    "    # params['rng'] = random_state\n",
    "    params['domain'] = domain\n",
    "        \n",
    "    # Update foldername to the full path \n",
    "    folder_name = params['storage_path'] + params['folder_location'] + params['folder_name']\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    params['folder_name'] = folder_name\n",
    "    \n",
    "    torch.set_num_threads(torch.get_num_threads())\n",
    "    \n",
    "    # Save model_params as a separate key in params also\n",
    "    params[f'{autoencoder.lower()}_hypers'] = model_params # Cortex hyperparameter dictionaries \n",
    "    \n",
    "    # Experiment\n",
    "    experiment = Experiment(**params)    \n",
    "    # experiment.train_autoencoder()\n",
    "    experiment.train_autoencoder_gnn()\n",
    "    # experiment.evaluate_trained_model()\n",
    "    # experiment.train_dBCQ_policy(params['pol_learning_rate'])\n",
    "    print('=' * 30)\n",
    "\n",
    "    pprint(params)\n",
    "    # with open(folder_name + '/config.yaml', 'w') as y:\n",
    "    #     yaml.safe_dump(params, y)  # saving params for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a37b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(autoencoder, domain, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72a836-6347-48dc-9f81-95ef9d8fafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load each thing to the graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d361a3-75bd-4d7a-a219-b7eec191885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that gets me a graph for a timestep t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f32da29-3932-4db5-8269-a701837cea2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4447b3-3be7-4579-972b-211a796a0569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-virtualenv-name",
   "language": "python",
   "name": "my-virtualenv-name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
