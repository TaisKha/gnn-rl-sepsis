{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07da54a-27c8-4145-acef-691d9a0261b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom stuff\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData, Batch\n",
    "\n",
    "class HeteroDataReplayBuffer(object):\n",
    "    def __init__(self, batch_size, buffer_size, device):\n",
    "        self.batch_size = batch_size\n",
    "        self.max_size = int(buffer_size)\n",
    "        self.device = device\n",
    "\n",
    "        # pointer where to add data\n",
    "        self.ptr = 0\n",
    "        # current size of the data\n",
    "        self.crt_size = 0\n",
    "\n",
    "        self.state = []\n",
    "        self.action = np.zeros((self.max_size, 1))\n",
    "        self.next_state = []\n",
    "        self.reward = np.zeros((self.max_size, 1))\n",
    "        self.not_done = np.zeros((self.max_size, 1))\n",
    "\n",
    "    def add(self, state, action, next_state, reward, done):\n",
    "        if len(self.state) < self.max_size:\n",
    "            self.state.append(state)\n",
    "            self.next_state.append(next_state)\n",
    "        else:\n",
    "            self.state[self.ptr] = state\n",
    "            self.next_state[self.ptr] = next_state\n",
    "\n",
    "        self.action[self.ptr] = action\n",
    "        self.reward[self.ptr] = reward\n",
    "        self.not_done[self.ptr] = 1. - done\n",
    "\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        self.crt_size = min(self.crt_size + 1, self.max_size)\n",
    "\n",
    "    def sample(self):\n",
    "        ind = np.random.randint(0, self.crt_size, size=self.batch_size)\n",
    "        \n",
    "        state_batch = Batch.from_data_list([self.state[i] for i in ind])\n",
    "        next_state_batch = Batch.from_data_list([self.next_state[i] for i in ind])\n",
    "\n",
    "        return (\n",
    "            state_batch.to(self.device),\n",
    "            torch.LongTensor(self.action[ind]).to(self.device),\n",
    "            next_state_batch.to(self.device),\n",
    "            torch.FloatTensor(self.reward[ind]).to(self.device),\n",
    "            torch.FloatTensor(self.not_done[ind]).to(self.device)\n",
    "        )\n",
    "\n",
    "    def save(self, save_folder):\n",
    "        torch.save(self.state[:self.crt_size], f\"{save_folder}_state.pt\")\n",
    "        np.save(f\"{save_folder}_action.npy\", self.action[:self.crt_size])\n",
    "        torch.save(self.next_state[:self.crt_size], f\"{save_folder}_next_state.pt\")\n",
    "        np.save(f\"{save_folder}_reward.npy\", self.reward[:self.crt_size])\n",
    "        np.save(f\"{save_folder}_not_done.npy\", self.not_done[:self.crt_size])\n",
    "        np.save(f\"{save_folder}_ptr.npy\", self.ptr)\n",
    "\n",
    "    def load(self, save_folder, size=-1):\n",
    "        reward_buffer = np.load(f\"{save_folder}_reward.npy\")\n",
    "        \n",
    "        # Adjust crt_size if we're using a custom size\n",
    "        size = min(int(size), self.max_size) if size > 0 else self.max_size\n",
    "        self.crt_size = min(reward_buffer.shape[0], size)\n",
    "\n",
    "        self.state = torch.load(f\"{save_folder}_state.pt\")[:self.crt_size]\n",
    "        self.action[:self.crt_size] = np.load(f\"{save_folder}_action.npy\")[:self.crt_size]\n",
    "        self.next_state = torch.load(f\"{save_folder}_next_state.pt\")[:self.crt_size]\n",
    "        self.reward[:self.crt_size] = reward_buffer[:self.crt_size]\n",
    "        self.not_done[:self.crt_size] = np.load(f\"{save_folder}_not_done.npy\")[:self.crt_size]\n",
    "\n",
    "        print(f\"Replay Buffer loaded with {self.crt_size} elements.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07276edb-9ae1-44dc-b252-8a9c3fccad3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (3886481327.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    replay_buffer = HeteroDataReplayBuffer(batch_size=batch_size, buffer_size=buffer_size, device)\u001b[0m\n\u001b[0m                                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "# we want that all the past experiences fit there as we don't interract with any en\n",
    "train_test_ratio = 0.8\n",
    "number_of_trajectories = 19000\n",
    "buffer_size = train_test_ratio * 19000\n",
    "replay_buffer = HeteroDataReplayBuffer(batch_size=batch_size, buffer_size=buffer_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7a84ac-338c-442e-ac60-2aa6a15ec212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose 80% of positive trajectories and save them in the list. use the analysis notebook for that.\n",
    "# choose 80% of negative trajectories and save\n",
    "# shuffle train trajectories\n",
    "# iterate over each train trajectory\n",
    "#     query neo4j to get trajectory graph\n",
    "#     set history of 1 extra node -> iterate over every timestep to create "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b039dd5-bfa8-47dd-9e6f-072aa4dfdd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_trajectory_from_neo4j, Neo4jConnection\n",
    "\n",
    "# Initialize the Neo4j driver\n",
    "neo4j_connection = Neo4jConnection()\n",
    "driver = neo4j_connection.get_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c52fb7-f84b-4b4b-a85b-633ff9a342f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f534f16-5091-43eb-8fff-09b86c4b2f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subgraph(step_idx):\n",
    "    start_idx = max(0, step_idx - history)\n",
    "        end_idx = step_idx\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675ffa3d-0cca-498d-bbb2-a6ecd7f153c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_replay_buffer(replay_buffer, history=1):\n",
    "\n",
    "for traj in ids:\n",
    "    patient, time_steps, actions = get_trajectory_from_neo4j(driver=driver, traj=traj)\n",
    "    \n",
    "    n_time_steps = len(time_steps)\n",
    "    next_obs = None\n",
    "\n",
    "    for step_idx in range(n_time_steps):\n",
    "        # Applying ReLu basically to make sure that history\n",
    "        # substracting does not result into negative indice\n",
    "        \n",
    "        \n",
    "        obs = next_obs if next_obs is not None else create_subgraph(patient, time_steps, step_idx)\n",
    "        action = pass\n",
    "        done = pass\n",
    "        reward = pass\n",
    "        if not done:\n",
    "            next_obs = create_subgraph(patient, time_steps, step_idx)\n",
    "        replay_buffer.add(obs, action, reward, next_obs)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-virtualenv-name",
   "language": "python",
   "name": "my-virtualenv-name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
